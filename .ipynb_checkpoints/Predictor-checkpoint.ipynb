{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Goal\n",
    "\n",
    "With this project we will try to train a neural network to predict whether the Indian stock market closing index Nifty will rise or fall on a particular date, based on historical values (1/1/2017 to 17/5/2019).\n",
    "\n",
    "Other than the standard OHLC (Open, High, Low, Close) data obtained from the National Stock Exchange(NSE), we will calculate a number of market indiactor to improve the accuracy of the model. \n",
    "\n",
    "#### 1.Ultimate Oscillator (UO)\n",
    "#### 2. Ulcer Index (UI)\n",
    "#### 3. Pring's know sure thing (KST)\n",
    "#### 4. Relative Vigour Index (RVI)\n",
    "#### 5. Positive Volume Index (PVI)\n",
    "#### 6. Market Facilitation Index (MFI)\n",
    "#### 7. Intraday Momentum Oscillator (IMI)\n",
    "#### 8. Elder's Force Index (EFI)\n",
    "#### 9. Detrended Price Oscillator (DPO)\n",
    "#### 10. Chande Momentum Oscillator (CMO)\n",
    "#### 11. Aroon Oscillator (AO)\n",
    "#### 12. Fisher Transformation (FT)\n",
    "#### 13. Mcginley Dynamic (McD)\n",
    "#### 14. Return On Interest (ROI) \n",
    "#### 15. Relative Strength Index (RSI)\n",
    "#### 16. Exponential Moving Average (EMA)\n",
    "#### 17. Moving Average Convergence and Divergence (MACD)\n",
    "#### 18. Stochastic Relative Strength Index (SRSI)\n",
    "#### 19. Williams %R Oscillator (Williams)\n",
    "#### 20. Average True Range (ATR)\n",
    "#### 21. Commodity Channel Index (CCI)\n",
    "\n",
    "How the value of each indicator is calculated has been explained below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1b11ff68defc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnsepy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from datetime import date\n",
    "from nsepy import get_history\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import functools\n",
    "import math\n",
    "from sklearn import preprocessing as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "Load data using the NSEpy API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_history(symbol=\"BIOCON\", start=date(2017,1,1), end=date(2019,7,3), index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observe data in graph\n",
    "data.plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_bp_n(data,n,i): #calculates the sum of Buying Pressure over the last 7 days\n",
    "    arr = []\n",
    "    for j in range(0,n):\n",
    "        bp = data.Close[i-j] - min(data.Low[i-j],data.Close[i-j-1])\n",
    "        arr.append(bp)\n",
    "    return sum(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_tr_n(data,n,i): #calculates the sum of True Range over the last 7 days\n",
    "    arr = []\n",
    "    for j in range(0,n):\n",
    "        tr = max(data.High[i-j],data.Close[i-j-1]) - min(data.Low[i-j],data.Close[i-j-1])\n",
    "        arr.append(tr)\n",
    "    return sum(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ultimate Oscillator\n",
    "\n",
    "Buying Pressure (BP) = Close - Min {Low, Prev Close}\n",
    "True Range (TR) = Max {High, Prev Close} - Min {Low, Prev Close}\n",
    "\n",
    "AV7 = Sum of BP over last 7 days / Sum of TR for last 7 days \n",
    "AV14 = Sum of BP over last 14 days / Sum of TR for last 14 days \n",
    "AV28 = Sum of BP over last 28 days / Sum of TR for last 28 days\n",
    "\n",
    "#### Ultimate Oscillator (UO) = [( AV7*4 + AV14*2 + AV28*1) / (4 + 2 + 1)]\n",
    "\n",
    "sum_bp_n and sum_tr_n are functions used to calculate the Buying Pressure and True Range respectively over a specified range (n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d7ad7bd746a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0muo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mult_Oscill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'UO'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "def ult_Oscill(data):\n",
    "    n = len(data)\n",
    "    arr = []\n",
    "    \n",
    "    for i in range(0,27):\n",
    "        arr.append('N')\n",
    "    \n",
    "    for i in range(27,n):\n",
    "        \n",
    "        bp_7 = sum_bp_n(data,7,i)\n",
    "        bp_14 = sum_bp_n(data,14,i)\n",
    "        bp_28 = sum_bp_n(data,28,i)\n",
    "\n",
    "        tr_7 = sum_tr_n(data,7,i)\n",
    "        tr_14 = sum_tr_n(data,14,i)\n",
    "        tr_28 = sum_tr_n(data,28,i)\n",
    "        \n",
    "        av_7 = bp_7/tr_7\n",
    "        av_14 = bp_14/tr_14\n",
    "        av_28 = bp_28/tr_28\n",
    "        \n",
    "        uo = ( (av_7)*4 + (av_14)*2 + (av_28)*1 )*100/(4+2+1)\n",
    "        \n",
    "        arr.append(uo)\n",
    "    return arr\n",
    "\n",
    "uo = ult_Oscill(data)\n",
    "print(len(uo))\n",
    "data['UO'] = uo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_per_High_Close is used to calculate the highest closing price over the previous n periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_per_High_Close(data,n,i): #Highest closing price in previous n days\n",
    "    arr = []\n",
    "    for j in range(0,n):\n",
    "        close = data.Close[i-j]\n",
    "        arr.append(close)\n",
    "    return max(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_per_Sum_pdd is used to calculate the percentage drawdown over n periods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_per_Sum_pdd(data,n,i): #n period sum of Percentage Drawdown\n",
    "    arr = []\n",
    "    for j in range(0,n):\n",
    "        HCls_14 = n_per_High_Close(data,14,i)\n",
    "        pdd = (data.Close[i-j] - HCls_14)*100/HCls_14 #Percentage Drawdown\n",
    "        arr.append(pdd)\n",
    "    return sum(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ulcer Index\n",
    "\n",
    "The indicator is calculated in three steps:\n",
    "\n",
    "Percentage drawdown = [(Close - 14 Period High of closes) / 14 Period High of Closes] *100\n",
    "Squared Avg = (14 Period sum of Percentage drawdown) / 14\n",
    "\n",
    "#### Ulcer Index = SQRT (Squared Avg)\n",
    "\n",
    "The Ulcer Index is used to determine the downside risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ulc_Index(data):\n",
    "    n = len(data)\n",
    "    arr = []\n",
    "    \n",
    "    for i in range(0,14):\n",
    "        arr.append('N')\n",
    "    \n",
    "    for i in range(14,n):\n",
    "        sq_av = n_per_Sum_pdd(data,14,i)/14\n",
    "        ui = math.sqrt(abs(sq_av))\n",
    "        arr.append(ui)\n",
    "    return arr\n",
    "\n",
    "ui = ulc_Index(data)\n",
    "#print(len(ui))\n",
    "data['UI'] = ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_per_SMA is used to calculate the Simple Moving Average (SMA) over the last n periods. \n",
    "SMA = (A1 + A2 + ... + An)/n, where Ai is the value i periods prior to the current period.\n",
    "Note that for n_per_SMA and n_per_ROC we have passed seperate arrays instead of using data directly from the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_per_SMA(arr,n): \n",
    "    sum = 0\n",
    "    l = len(arr)\n",
    "    for j in range(0,n):\n",
    "        sum = sum + arr[l-j-1]\n",
    "    return (sum/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_per_ROC is used to calculate the Rate of Change. \n",
    "ROC = 100*(Close[i]-Close[i-n])/Close[i-n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_per_ROC(arr,n,i):\n",
    "    arr1 = []\n",
    "    for j in range(0,n):\n",
    "        roc = (arr[i-j]-arr[i-j-n])*100/n\n",
    "        arr1.append(roc) \n",
    "    return arr1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pring's Know Sure Thing (KST)\n",
    "\n",
    "#### KST = (RCMA#1*1) + (RCMA#2*2) + (RCMA#3*3) + (RCMA#4*4) where\n",
    "\n",
    "RCMA#1 = 10 period SMA of 10 period ROC \n",
    "RCMA#2 = 10 period SMA of 15 period ROC \n",
    "RCMA#3 = 10 period SMA of 20 period ROC \n",
    "RCMA#4 = 15 period SMA of 30 period ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KST(data): #Pring's Know Sure Thing\n",
    "    arr = []\n",
    "    n = len(data)\n",
    "    for i in range(0,30):\n",
    "        arr.append('N')\n",
    "    for i in range(30,n):\n",
    "        RCMA_1 = n_per_SMA(n_per_ROC(data.Close.tolist(),10,i),10)\n",
    "        RCMA_2 = n_per_SMA(n_per_ROC(data.Close.tolist(),15,i),10)\n",
    "        RCMA_3 = n_per_SMA(n_per_ROC(data.Close.tolist(),20,i),10)\n",
    "        RCMA_4 = n_per_SMA(n_per_ROC(data.Close.tolist(),30,i),15)\n",
    "        kst = 1*RCMA_1 + 2*RCMA_2 + 3*RCMA_3 + 4*RCMA_4\n",
    "        arr.append(kst)\n",
    "    return arr\n",
    "\n",
    "arr = KST(data)\n",
    "data['KST'] = arr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative Vigor Index (RVI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RVI(data): #incomplete\n",
    "    n = len(data)\n",
    "    for i in range(3,n):\n",
    "        a = data.Close[i] - data.Open[i]\n",
    "        b = data.Close[i-1] - data.Open[i-1]\n",
    "        c = data.Close[i-2] - data.Open[i-2]\n",
    "        d = data.Close[i-3] - data.Open[i-3]\n",
    "        \n",
    "        e = data.High[i] - data.Low[i]\n",
    "        f = data.High[i-1] - data.Low[i-1]\n",
    "        g = data.High[i-2] - data.Low[i-2]\n",
    "        h = data.High[i-3] - data.Low[i-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive Volume Index (PVI)\n",
    "\n",
    "Helps infer if smart money (institutional investor money) is pouring in / out. \n",
    "\n",
    "If today’s volume is ​higher​ than previous day’ volume\n",
    "PVI = Previous PVI + [(Today’s Close - Prev Close) / Prev Close] * Previous PVI \n",
    "\n",
    "ELSE\n",
    "PVI unchanged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PVI(data): #Positive Volume Index\n",
    "    pvi = data.Volume[0] #I'm assuming the base case is the volume on the first day for which data is available. \n",
    "    arr = []\n",
    "    arr.append('N')\n",
    "    n = len(data)\n",
    "    for i in range(1,n):\n",
    "        if data.Volume[i] > data.Volume[i-1]:\n",
    "            pvi = pvi + ((data.Close[i]-data.Close[i-1])/data.Close[i-1])*pvi\n",
    "        arr.append(pvi)\n",
    "    return arr\n",
    "\n",
    "arr = PVI(data)\n",
    "data['PVI'] = arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Volume Index (NVI)\n",
    "\n",
    "If today’s volume is ​lower​ than previous day’s volume\n",
    "NVI = Previous NVI + [(Today’s Close - Prev Close) / Prev Close] * Previous NVI \n",
    "\n",
    "ELSE\n",
    "NVI unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NVI(data): #Negative Volume Index\n",
    "    nvi = data.Volume[0] #I'm assuming the base case is the volume on the first day for which data is available. \n",
    "    arr = []\n",
    "    arr.append('N')\n",
    "    n = len(data)\n",
    "    for i in range(1,n):\n",
    "        if data.Volume[i] < data.Volume[i-1]:\n",
    "            nvi = nvi + ((data.Close[i]-data.Close[i-1])/data.Close[i-1])*nvi\n",
    "        arr.append(nvi)\n",
    "    return arr\n",
    "\n",
    "arr = NVI(data)\n",
    "data['NVI'] = arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market Facilitation Index\n",
    "\n",
    "#### MFI = (High - Low) / Volume\n",
    "Basically price change per unit volume. Note that since volumes are very large MFI is a small value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFI(data): #Market Facilitation Index\n",
    "    arr = []\n",
    "    n = len(data)\n",
    "    for i in range(0,n):\n",
    "        mfi = (data.High[i]-data.Low[i])/data.Volume[i]\n",
    "        arr.append(mfi)\n",
    "    return arr\n",
    "\n",
    "arr = MFI(data)\n",
    "data['MFI'] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_gains_losses(data,n,i):\n",
    "    g = []\n",
    "    l = []\n",
    "    for j in range(0,n):\n",
    "        if data.Close[i-j]>data.Close[i-j-1]:\n",
    "            g.append(data.Close[i-j]-data.Close[i-j-1])\n",
    "        else:\n",
    "            l.append(data.Close[i-j-1]-data.Close[i-j])\n",
    "    sum_gains = sum(g)\n",
    "    sum_losses = sum(l)\n",
    "    return sum_gains,sum_losses "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intraday Momentum Oscillator\n",
    "\n",
    "#### IMI = (Sum of Gains over N days) / (Sum of Gains over N days + Sum of losses over N days)\n",
    "\n",
    "if Close today > Close yesterday Gain = Close today - Close yesterday\n",
    "\n",
    "Else if Close today < Close yesterday Loss = Close Yesterday - Close today\n",
    "\n",
    "For now I have taken N as 14 but this can be easily changed\n",
    "Similar purpose as RSI...incorporates graphical features and trading psychology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IMI(data): #Intraday Momentum Oscillator\n",
    "    n = len(data)\n",
    "    arr = []\n",
    "    for i in range(0,14):\n",
    "        arr.append('N')\n",
    "    for i in range(14,n):\n",
    "        s_g,s_l = sum_gains_losses(data,14,i) #Change the 14 to X to change period (3 times)\n",
    "        imi = (s_g)/(s_g+s_l)\n",
    "        arr.append(imi)\n",
    "    return arr\n",
    "\n",
    "arr = IMI(data)\n",
    "data['IMI'] = arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elder's Force Index\n",
    "#### Elder’s Force Index = (Close (Today) - Close (Yesterday)) * Today’s Volume\n",
    "\n",
    "Measures strength of an up move or down move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EFI(data): #Elder's Force Index\n",
    "    arr = []\n",
    "    arr.append('N')\n",
    "    n = len(data)\n",
    "    for i in range(1,n):\n",
    "        efi = (data.Close[i]-data.Close[i-1])*data.Volume[i]\n",
    "        arr.append(efi)\n",
    "    return arr\n",
    "arr = EFI(data)\n",
    "data['EFI'] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_per_SMA(arr,n,i): \n",
    "    sum = 0\n",
    "    for j in range(0,n):\n",
    "        sum = sum + arr[i-j-1]\n",
    "    return (sum/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detrended Price Oscillator\n",
    "\n",
    "Let us say lookback period is N. Taking as 14 for now\n",
    "\n",
    "#### DPO = Close (N/2 + 1 periods ago) - SMA of close (Last N periods)\n",
    "\n",
    "Great for short term / intraday trades as it puts emphasis on short term cycles and filters out the long term trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DPO(data): #Detrended Price Oscillator\n",
    "    l = 14 #Lookback Period\n",
    "    n = len(data)\n",
    "    arr = []\n",
    "    for i in range(0,l):\n",
    "        arr.append('N')\n",
    "    for i in range(l,n):\n",
    "        sma = n_per_SMA(data.Close,l,i)\n",
    "        dpo = data.Close[i-((l//2)+1)] - sma\n",
    "        arr.append(dpo)\n",
    "    return arr\n",
    "\n",
    "arr = DPO(data)\n",
    "data['DPO'] = arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Range (TR) = Maximum of 1) High - Low\n",
    "                             2) Modulus of (High - Previous Close) \n",
    "                             3) Modulus of (Low - Previous Close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TR(data,i): #True Range \n",
    "    a = data.High[i] - data.Low[i]\n",
    "    b = abs(data.High[i] - data.Close[i-1])\n",
    "    c = abs(data.Low[i] - data.Close[i-1])    \n",
    "    tr = max(a,b,c)\n",
    "    return tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average True Range\n",
    "\n",
    "#### ATR  = (Summation of TR for past n days) / n\n",
    "\n",
    "It is a ​volatility measurer ​and is very useful for trading options. Might help in stocks as high ATR generally signifies downtrend.\n",
    "Taking N as 14 for now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_per_sum_TR(data,n,i): #Calculates the sum of the TR for the past n periods\n",
    "    arr = []\n",
    "    for j in range(0,n):\n",
    "        arr.append(TR(data,i-j))\n",
    "    return sum(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_per_ATR(data,n):\n",
    "    arr = []\n",
    "    for i in range(0,n):\n",
    "        arr.append('N')\n",
    "    for i in range(n,len(data)):\n",
    "        sum = n_per_sum_TR(data,n,i)\n",
    "        atr = sum/n\n",
    "        arr.append(atr)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = n_per_ATR(data,14)\n",
    "data['ATR_14'] = arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chande Momentum Oscillator\n",
    "\n",
    "#### CMO = [ (sH-sL) / (sH+sL) ] * 100\n",
    "sH = Sum of higher closes over N periods sL = Sum of lower closes over N periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_per_CMO(data,n): #Chande Momentum Oscillator\n",
    "    arr = []\n",
    "    for i in range(0,n):\n",
    "        arr.append('N')\n",
    "    for i in range(n,len(data)):\n",
    "        hc = [] #High Closes in the last n periods. A high close is the close when the closing price is greater than opening price\n",
    "        lc = [] #Low Closes in the last n periods\n",
    "        for j in range(0,n):\n",
    "            if data.Close[i-j]>data.Open[i-j]:\n",
    "                hc.append(data.Close[i-j])\n",
    "            else:\n",
    "                lc.append(data.Close[i-j])\n",
    "        sH = sum(hc)\n",
    "        sL = sum(lc)\n",
    "        cmo = ( (sH-sL)/(sH+sL) )*100\n",
    "        arr.append(cmo)\n",
    "    return arr\n",
    "\n",
    "arr = n_per_CMO(data,14) #Taking N = 14 for now\n",
    "data['CMO'] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pers_since_n_per_High_Close(data,n,i): #Periods (days) since highest closing price in previous n days\n",
    "    arr = []\n",
    "    for j in range(0,n):\n",
    "        close = data.Close[i-j]\n",
    "        arr.append(close)\n",
    "    for j in range(0,n):\n",
    "        if float(arr[j]) == max(arr):\n",
    "            return n-j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pers_since_n_per_Low_Close(data,n,i): #Periods (days) since lowest closing price in previous n days\n",
    "    arr = []\n",
    "    for j in range(0,n):\n",
    "        close = data.Close[i-j]\n",
    "        arr.append(close)\n",
    "    for j in range(0,n):\n",
    "        if float(arr[j]) == min(arr):\n",
    "            return n-j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aroon Oscillator (Up)\n",
    "\n",
    "#### Aroon Up = 100 * (n - periods since period high) / 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_per_AO_up(data,n): #n period Aroon Oscillator\n",
    "    arr = []\n",
    "    for i in range(0,n):\n",
    "        arr.append('N')\n",
    "    for i in range(n,len(data)):\n",
    "        p_h = pers_since_n_per_High_Close(data,n,i)\n",
    "        a_up = 100*(n - p_h)/n\n",
    "        arr.append(a_up)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aroon Oscillator (Down)\n",
    "#### Aroon Down = 100 * (25 - periods since 25 period low) / 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_per_AO_down(data,n): #n period Aroon Oscillator\n",
    "    arr = []\n",
    "    for i in range(0,n):\n",
    "        arr.append('N')\n",
    "    for i in range(n,len(data)):\n",
    "        p_l = pers_since_n_per_Low_Close(data,n,i)\n",
    "        a_down = 100*(n - p_l)/n\n",
    "        arr.append(a_down)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aroon_up = n_per_AO_up(data,25)\n",
    "aroon_down = n_per_AO_down(data,25)\n",
    "\n",
    "data['AO_up'] = aroon_up\n",
    "data['AO_down'] = aroon_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(arr): #transforms the elements of the input array to values between -1 and 1\n",
    "    arr1 = np.zeros(len(arr))\n",
    "    for i in range(0,len(arr)):\n",
    "        arr1[i] = 2*((arr[i]-min(arr))/(max(arr)-min(arr))) - 1\n",
    "        if float(arr1[i]) == 1.0:\n",
    "            arr1[i] = 0.9999\n",
    "        elif float(arr1[i]) == -1.0:\n",
    "            arr1[i] = -0.9999\n",
    "    return arr1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fisher Transformation\n",
    "\n",
    "#### Fisher Transform (FT) = 0.5 * ln( (1+X) / (1-X) )\n",
    "Where ln is natural logarithm and X is transformation of price to a value between -1 and 1. FT converts prices to a Gaussian Normal Distribution helping identify reversals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_per_FT(arr,n): #Fisher Transform\n",
    "    arr1 = []\n",
    "    for i in range(0,n):\n",
    "        arr1.append('N')\n",
    "    for i in range(n,len(arr)):\n",
    "        ft = 0.5*(math.log(abs((1+arr[i])/(1-arr[i]))))\n",
    "        arr1.append(ft)\n",
    "    return arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_t = data.Close\n",
    "arr = n_per_FT(transform(close_t),14)\n",
    "data['FT'] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WC(data): #Weighted Close \n",
    "    arr = []\n",
    "    n = len(data)\n",
    "    for i in range(0,n):\n",
    "        wc = (data.High[i]+data.Low[i]+2*data.Close[i])/4\n",
    "        arr.append(wc)\n",
    "    return arr\n",
    "\n",
    "arr = WC(data)\n",
    "data['WC'] = arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## McGinley Dynamic\n",
    "\n",
    "#### MD = Prev_MD + (Close - Prev_MD) / (K*N*(Close / Prev_MD)4​ ​)\n",
    "Where\n",
    "\n",
    "MD = McGinley Dynamic \n",
    "\n",
    "Prev_MD = Previous McGinley Dynamic\n",
    "\n",
    "N = no. of periods over which you want smoothening\n",
    "\n",
    "K = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_per_McD(data,n): #McGinley Dynamic #n is the number of periods over which you want smoothening\n",
    "    arr = []\n",
    "    arr.append(data.Close[0]) \n",
    "    for i in range(1,len(data)):\n",
    "        c = (data.Close[i]/arr[i-1])**4\n",
    "        md = arr[i-1] + ((data.Close[i]-arr[i-1])/(0.6*n*c))\n",
    "        arr.append(md)\n",
    "    return arr\n",
    "\n",
    "arr = n_per_McD(data,20) #Change length by changing this 20\n",
    "data['MD_20'] = arr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum\n",
    "\n",
    "#### Momentum = latest closing price - closing price n periods ago\n",
    "\n",
    "Market momentum is measured by continually taking price differences for a fixed time interval. To construct a 10-day momentum line, simply subtract the closing price 10 days ago from the last closing price. This positive or negative value is then plotted around a zero line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-day momentum\n",
    "def momentum(df):\n",
    "    n = len(df)\n",
    "    arr = []\n",
    "    for i in range(0,5):\n",
    "        arr.append('N')\n",
    "    for j in range(5,n):\n",
    "        momentum = df.Close[j] - df.Close[j-5] #Equation for momentum\n",
    "        arr.append(momentum)\n",
    "    return arr\n",
    "\n",
    "momentum = momentum(data)\n",
    "data['Momentum'] = momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return\n",
    "\n",
    "#### Return = (Close[i] - Close[i-1])/Close[i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pctchange=data.Close.pct_change()\n",
    "data['Return'] = data_pctchange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return On Interest\n",
    "\n",
    "#### ROI = (closing price today - closing price n periods ago) / closing price n periods ago\n",
    "\n",
    "Return on Investment (ROI) is a performance measure used to evaluate the efficiency of an investment or compare the efficiency of a number of different investments. ROI tries to directly measure the amount of return on a particular investment, relative to the investment’s cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROI(df,n): #Return On Interest\n",
    "    m = len(df)\n",
    "    arr = []\n",
    "    for i in range(0,n):\n",
    "        arr.append('N')\n",
    "    for j in range(n,m):\n",
    "        roi= (df.Close[j] - df.Close[j-n])/df.Close[j-n] #Equation for ROI\n",
    "        arr.append(roi)\n",
    "    return arr\n",
    "ROI10=ROI(data,10)\n",
    "ROI20=ROI(data,20)\n",
    "ROI30=ROI(data,30)\n",
    "data['10 Day ROI']=ROI10\n",
    "data['20 Day ROI']=ROI20\n",
    "data['30 Day ROI']=ROI30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative Strength Index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSI(df,period): #Relative Strength Index\n",
    "    # get average of upwards of last 14 days: Ct - Ct-1\n",
    "    # get average of downwards of last 14 days: Ct-1 - Ct\n",
    "    n = len(df)\n",
    "    arr = []\n",
    "    for i in range(0,period):\n",
    "        arr.append('N')\n",
    "    for j in range(period,n):\n",
    "        total_upwards = 0\n",
    "        total_downwards = 0\n",
    "        # this will find average of upwards\n",
    "        for k in range(j,j-period,-1):\n",
    "            if(df.Close[k-1] > df.Close[k]):\n",
    "                total_downwards = total_downwards + (df.Close[k-1] - df.Close[k])    \n",
    "        avg_down = total_downwards / period\n",
    "        for l in range(j,j-period,-1):\n",
    "            if(df.Close[l] > df.Close[l-1]):\n",
    "                total_upwards = total_upwards + (df.Close[l] - df.Close[l-1])\n",
    "        avg_up = total_upwards / period\n",
    "        RS = avg_up / avg_down\n",
    "        RSI  = 100 - (100/(1+RS))\n",
    "        arr.append(RSI)\n",
    "    return arr\n",
    "\n",
    "RSI_17 = RSI(data,17)\n",
    "RSI_14 = RSI(data,14)\n",
    "RSI_10 = RSI(data,10)\n",
    "RSI_30 = RSI(data,30)\n",
    "data['17_day_RSI'] = RSI_17\n",
    "data['10_day_RSI'] = RSI_10\n",
    "data['14_day_RSI'] = RSI_14\n",
    "data['30_day_RSI'] = RSI_30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential Moving Average\n",
    "\n",
    "The exponential moving average (EMA) is a weighted moving average (WMA) that gives more weighting, or importance, to recent price data than the simple moving average (SMA) does. The EMA responds more quickly to recent price changes than the SMA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EMA(df, n): #Exponential Moving Average\n",
    "    m = len(df)\n",
    "    arr = []\n",
    "    arr.append('N')\n",
    "    prevEMA = df.Close[0]\n",
    "    for i in range(1,m):\n",
    "        close = df.Close[i]\n",
    "        EMA = ((2/(n+1))*close) + ((1-(2/(n+1)))*prevEMA)\n",
    "        arr.append(EMA)\n",
    "        prevEMA = EMA\n",
    "    return arr\n",
    "EMA_12 = EMA(data, 12)\n",
    "EMA_26 = EMA(data, 26)\n",
    "data['EMA_12'] = EMA_12\n",
    "data['EMA_26'] = EMA_26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EMA_arr(array, n): #Exponential Moving Average of any array\n",
    "    m = len(array)\n",
    "    arr = []\n",
    "    arr.append(0)\n",
    "    prevEMA = array[0]\n",
    "    for i in range(1,m):\n",
    "        close = array[i]\n",
    "        EMA = ((2/(n+1))*close) + ((1-(2/(n+1)))*prevEMA)\n",
    "        arr.append(EMA)\n",
    "        prevEMA = EMA\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Average Convergence and Divergence (MACD)\n",
    "\n",
    "#### MACD = 12 day EMA of stock - 26 day EMA of stock \n",
    "\n",
    "However, we shall not use this directly\n",
    "\n",
    "Signal Line(SG) = 9 day EMA of MACD\n",
    "\n",
    "New MACD = MACD - SG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MACD\n",
    "# Moving Average of EMA(n) - EMA(m2) for each row\n",
    "# where n = 12 and m2 = 26\n",
    "def MACD(df):\n",
    "    n = 12\n",
    "    m2 = 26\n",
    "    arr = []\n",
    "    arr.append(0)\n",
    "    ema_12 = EMA(df,n)\n",
    "    ema_26 = EMA(df,m2)\n",
    "    m = len(df)\n",
    "    for i in range(1,m):\n",
    "        arr.append(ema_12[i] - ema_26[i])\n",
    "    return arr\n",
    "\n",
    "MACD = MACD(data)\n",
    "SG = EMA_arr(MACD,9)\n",
    "arr = []\n",
    "for i in range(len(MACD)):\n",
    "    arr = MACD[i] - SG[i]\n",
    "data['MACD'] = arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic RSI \n",
    "\n",
    "#### SRSI = (Latest RSI - Lowest RSI in N days) / (Highest RSI in N days - Lowest RSI in N days)\n",
    "\n",
    "N is generally 14 for both RSI and SRSI but note that N MUST BE SAME for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SRSI: Stochastic RSI\n",
    "#SRSI = (RSI_today - min(RSI_past_n)) / (max(RSI_past_n) - min(RSI_past_n))\n",
    "def SRSI(df,n):\n",
    "    m = len(df)\n",
    "    arr = []\n",
    "    list_RSI = RSI(df,n)\n",
    "    for i in range(0,n):\n",
    "        arr.append('N')\n",
    "    for j in range(n,n+n):\n",
    "        last_n = list_RSI[n:j]\n",
    "        if(not(last_n == []) and not(max(last_n) == min(last_n))):\n",
    "            SRSI = (list_RSI[j] - min(last_n)) / (max(last_n)- min(last_n))\n",
    "            if SRSI > 1:\n",
    "                arr.append(1)\n",
    "            else:\n",
    "                arr.append(SRSI)\n",
    "        else:\n",
    "            arr.append(0)\n",
    "    for j in range(n+n,m):\n",
    "        last_n = list_RSI[2*n:j]\n",
    "        if(not(last_n == []) and not(max(last_n) == min(last_n))):\n",
    "            SRSI = (list_RSI[j] - min(last_n)) / (max(last_n)- min(last_n))\n",
    "            if SRSI > 1:\n",
    "                arr.append(1)\n",
    "            else:\n",
    "                arr.append(SRSI)\n",
    "        else:\n",
    "            arr.append(0)\n",
    "    return arr\n",
    "\n",
    "SRSI_10 = SRSI(data,10)\n",
    "SRSI_14 = SRSI(data,14)\n",
    "SRSI_30 = SRSI(data,30)\n",
    "SRSI_17 = SRSI(data,17)\n",
    "\n",
    "data['SRSI_17'] = SRSI_17\n",
    "data['SRSI_10'] = SRSI_10\n",
    "data['SRSI_14'] = SRSI_14\n",
    "data['SRSI_30'] = SRSI_30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## William's %R Ocsillator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Williams(df,n): #Williams %R oscillator for each day\n",
    "    m = len(df)\n",
    "    arr = []\n",
    "    for i in range(0,n-1):\n",
    "        arr.append('N')\n",
    "    for j in range(n-1,m):\n",
    "        maximum = max(data.High[(j-n+1):j+1])\n",
    "        minimum = min(data.Low[(j-n+1):j+1])\n",
    "        val = (-100)*(maximum-df.Close[j])/(maximum-minimum)\n",
    "        arr.append(val)\n",
    "    return arr\n",
    "williams = Williams(data,14)\n",
    "data['Williams'] = williams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average True Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Range\n",
    "# TR = MAX(high[today] - close[yesterday]) - MIN(low[today] - close[yesterday])\n",
    "def TR(df,n):\n",
    "    high = df.High[n]\n",
    "    low = df.Low[n]\n",
    "    close = df.Close[n-1]\n",
    "    l_max = list()\n",
    "    l_max.append(high)\n",
    "    l_max.append(close)\n",
    "    l_min = list()\n",
    "    l_min.append(low)\n",
    "    l_min.append(close)\n",
    "    return (max(l_max) - min(l_min))\n",
    "\n",
    "# Average True Range\n",
    "# Same as EMA except use TR in lieu of close (prevEMA = TR(dataframe,14days))\n",
    "def ATR(df,n):\n",
    "    m = len(df)\n",
    "    arr = []\n",
    "    prevEMA = TR(df,n+1)\n",
    "    for i in range(0,n):\n",
    "        arr.append('N')\n",
    "    for j in range(n,m):\n",
    "        TR_ = TR(df,j)\n",
    "        EMA = ((2/(n+1))*TR_) + ((1-(2/(n+1)))*prevEMA)\n",
    "        arr.append(EMA)\n",
    "        prevEMA = EMA\n",
    "    return arr\n",
    "\n",
    "ATR = ATR(data,14)  \n",
    "data['ATR_14'] = ATR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commodity Channel Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CCI(df,n):\n",
    "    m = len(df)\n",
    "    arr = []\n",
    "    tparr = []\n",
    "    for i in range(0,n-1):\n",
    "        arr.append('N')\n",
    "        tp = (df.High[i]+df.Low[i]+df.Close[i])/3\n",
    "        tparr.append(tp)\n",
    "    for j in range(n-1,m):\n",
    "        tp = (df.High[j]+df.Low[j]+df.Close[j])/3\n",
    "        tparr.append(tp) \n",
    "        tps = np.array(tparr[(j-5):(j+1)])\n",
    "        val = (tp-tps.mean())/(0.015*tps.std())\n",
    "        arr.append(val)\n",
    "    return arr\n",
    "\n",
    "cci = CCI(data,20) \n",
    "\n",
    "#Add CCI to our dataframe\n",
    "data['CCI'] = cci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[32:] #removing Ns\n",
    "data = data.astype(float)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "cols = data.columns\n",
    "std_scale = pp.StandardScaler().fit(data)\n",
    "arr = std_scale.transform(data)\n",
    "df_std = pd.DataFrame(arr)\n",
    "#because arr is a numpy array\n",
    "df_std.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# observe trend in data in graph\n",
    "df_std.plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std.columns = cols\n",
    "df_std.describe() #note that mean is 0 and std_dev is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make time series data stationary in the mean, thus having no trend in the data\n",
    "# applying log(Vt/Vt-1) on all data\n",
    "df_std_log = np.log(abs(df_std[cols]/df_std[cols].shift()))\n",
    "\n",
    "# remove first row (contains NaN because of the t-1 shift)\n",
    "df_std_log = df_std_log.iloc[1:]\n",
    "df_std_log.columns = data.columns\n",
    "df_std_log.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std_log['Down'] = 0\n",
    "df_std_log['Up'] = 0\n",
    "df_std_log.loc[df_std_log['Close'] >= 0, 'Up'] = 1\n",
    "df_std_log.loc[df_std_log['Close'] < 0, 'Down'] = 1\n",
    "#df_std = df_std_log\n",
    "df_std_log.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std = df_std[1:]\n",
    "df_std['Up'] = df_std_log['Up']\n",
    "df_std['Down'] = df_std_log['Down']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std.index = range(0,len(df_std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Blasting the outliers\n",
    "from scipy import stats\n",
    "z = pd.DataFrame(abs(stats.zscore(df_std,axis = 1)))\n",
    "z.columns = df_std.columns\n",
    "df_std = df_std[(z < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std.plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_std.columns\n",
    "cols = cols[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df_std[cols]\n",
    "dataset = dataset.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns[[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProvider():\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        self.ctr = 0\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # split training/testing according to ratio (default 0.8)\n",
    "        train_set_size = int(len(dataset) * 0.8)\n",
    "        test_set_size = len(dataset) - train_set_size\n",
    "\n",
    "        self.training_dataset = dataset[:train_set_size]\n",
    "        self.testing_dataset  = dataset[train_set_size:]\n",
    "\n",
    "        # split labels\n",
    "        self.training_labels = self.training_dataset[self.training_dataset.columns[:2]]\n",
    "        self.training_dataset = self.training_dataset[self.training_dataset.columns[2:]]\n",
    "        self.testing_labels = self.testing_dataset[self.testing_dataset.columns[:2]]\n",
    "        self.testing_dataset = self.testing_dataset[self.testing_dataset.columns[2:]]\n",
    "        \n",
    "    def next_batch_train(self):\n",
    "        begin_position = self.ctr * self.batch_size\n",
    "        \n",
    "        if begin_position + self.batch_size >= len(self.training_dataset):\n",
    "            data = self.training_dataset[begin_position:]\n",
    "            label = self.training_labels[begin_position:]\n",
    "            self.ctr = 0\n",
    "        else:\n",
    "            data = self.training_dataset[begin_position:begin_position + self.batch_size]\n",
    "            label = self.training_labels[begin_position:begin_position + self.batch_size]\n",
    "            self.ctr += 1\n",
    "        \n",
    "        return data.values, label.values\n",
    "    \n",
    "    def get_test_data(self):\n",
    "        return self.testing_dataset.values, self.testing_labels.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "no_of_iterations = 50000\n",
    "batch_size = 200 #?\n",
    "\n",
    "## model config\n",
    "hidden_layer1_neurons = 60\n",
    "hidden_layer2_neurons = 30\n",
    "hidden_layer3_neurons = 20\n",
    "\n",
    "# DropOut\n",
    "pkeep_train = 0.75 #?\n",
    "\n",
    "# number of features\n",
    "input_dim = len(dataset.columns) - 2\n",
    "\n",
    "# number of output classes\n",
    "output_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_provider = DataProvider(dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom decorator for Model\n",
    "#  - to make functions execute only the first time (every time the functions are called, the graph would be extended by new code)\n",
    "#  - name the variable scope for TF visualization\n",
    "def define_scope(function, scope=None):\n",
    "    attribute = '_cache_' + function.__name__\n",
    "\n",
    "    name = scope or function.__name__\n",
    "    @property\n",
    "    @functools.wraps(function)\n",
    "    def decorator(self):\n",
    "        if not hasattr(self, attribute):\n",
    "            with tf.variable_scope(name):\n",
    "                setattr(self, attribute, function(self))\n",
    "        return getattr(self, attribute)\n",
    "\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model description:\n",
    "Model consists of 3 hidden layers + 1 softmax output layer.\n",
    "Incorporates shootout while training to make inidividual neurons more independent on other layers and perform better.\n",
    "Incorporates learning rate decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, data, label, learning_rate):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.learning_rate = learning_rate\n",
    "        self.prediction\n",
    "        self.optimize\n",
    "        \n",
    "    @define_scope\n",
    "    def prediction(self):        \n",
    "        # weights + biases\n",
    "        w1 = tf.Variable(tf.truncated_normal([input_dim, hidden_layer1_neurons], stddev=0.0001))\n",
    "        b1 = tf.Variable(tf.ones([hidden_layer1_neurons]))\n",
    "\n",
    "        w2 = tf.Variable(tf.truncated_normal([hidden_layer1_neurons, hidden_layer2_neurons], stddev=0.0001))\n",
    "        b2 = tf.Variable(tf.ones([hidden_layer2_neurons]))\n",
    "\n",
    "        w3 = tf.Variable(tf.truncated_normal([hidden_layer2_neurons, hidden_layer3_neurons], stddev=0.0001))\n",
    "        b3 = tf.Variable(tf.ones([hidden_layer3_neurons]))\n",
    "        \n",
    "        w4 = tf.Variable(tf.truncated_normal([hidden_layer3_neurons, output_dim], stddev=0.0001))\n",
    "        b4 = tf.Variable(tf.ones([output_dim]))\n",
    "        \n",
    "        # hidden layers\n",
    "        Y1 = tf.nn.relu(tf.matmul(self.data, w1) + b1)\n",
    "        Y1d = tf.nn.dropout(Y1, pkeep)\n",
    "        Y2 = tf.nn.relu(tf.matmul(Y1, w2) + b2)\n",
    "        Y2d = tf.nn.dropout(Y2, pkeep)\n",
    "        Y3 = tf.nn.relu(tf.matmul(Y2, w3) + b3)\n",
    "        Y3d = tf.nn.dropout(Y3, pkeep)\n",
    "        \n",
    "        # softmax layer\n",
    "        return tf.nn.softmax(tf.matmul(Y3d, w4) + b4)\n",
    "    \n",
    "    @define_scope\n",
    "    def optimize(self):\n",
    "        # compute cost function and minimize\n",
    "        cross_entropy = -tf.reduce_sum(self.label * tf.log(self.prediction))\n",
    "        return tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy), cross_entropy\n",
    "    \n",
    "    @define_scope\n",
    "    def error(self):\n",
    "        mistakes = tf.equal(tf.argmax(self.label, 1), tf.argmax(self.prediction, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(mistakes, tf.float32))\n",
    "        loss = -tf.reduce_sum(self.label * tf.log(self.prediction))\n",
    "        return accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data feed\n",
    "X = tf.placeholder(tf.float32, [None, input_dim])\n",
    "_Y = tf.placeholder(tf.float32, [None, output_dim])\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "\n",
    "# DropOut: feed in 1 when testing, 0.75 when training\n",
    "pkeep = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(data=X, label=_Y, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "accuracy = []\n",
    "_loss = []\n",
    "for i in range(no_of_iterations):\n",
    "    # execute training step\n",
    "    # optimizer learning rate decay\n",
    "    lrmax = 0.001\n",
    "    lrmin = 0.00001\n",
    "    lr = lrmin + (lrmax - lrmin) * math.exp(-i / 2000)\n",
    "    \n",
    "    data_batch, label_batch = data_provider.next_batch_train()\n",
    "    sess.run(model.optimize, feed_dict={X: data_batch, _Y: label_batch, learning_rate:lr, pkeep: pkeep_train})\n",
    "    \n",
    "    if i % 500 == 0:\n",
    "        # compute accuracy\n",
    "        data_batch, label_batch = data_provider.get_test_data()\n",
    "        acc, loss = sess.run(model.error, feed_dict={X: data_batch, _Y: label_batch, pkeep: 1})\n",
    "        accuracy.append(acc)\n",
    "        _loss.append(loss)\n",
    "        print('---epoch {}---\\naccuracy: {}, loss: {}'.format(i // 500, acc, loss))\n",
    "\n",
    "print('Training finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy on test data\n",
    "data_batch, label_batch = data_provider.get_test_data()\n",
    "acc, loss = sess.run(model.error, feed_dict={X: data_batch, _Y: label_batch, pkeep: 1})\n",
    "print('Test: accuracy={}, loss={}'.format(acc, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,6))\n",
    "\n",
    "# accuracy\n",
    "plt.subplot(211)\n",
    "plt.plot(accuracy)\n",
    "\n",
    "# loss\n",
    "plt.subplot(212)\n",
    "plt.plot(np.log(_loss))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
